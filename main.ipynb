{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Data \n",
    "\n",
    "1. The Data will be retrieved using reddit praw, the data will be found through going through reddit's 25 most popular story telling subreddits\n",
    "2. The retrieved data will include for each instance of a post: \n",
    "    - id: to keep track\n",
    "    - title: first taste of the story\n",
    "    - the story within the post: main point of analysis\n",
    "    - the time it was created: time of story post might be related to success of story\n",
    "    - the subreddit it was made within: the followers of each subreddit could cause more success\n",
    "    - number of comments: more conversation means better story\n",
    "    - upvote amount: more upvotes means better story as well\n",
    "    - upvote ratio: important to understand downvotes which a marker for poor story telling\n",
    "3. For each subreddit, we will aim towards getting 1000 posts but sometimes reddit does not allow for that amount, but it will be about 25,000 posts from 25 unique subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "from textblob import TextBlob\n",
    "reddit = praw.Reddit(\n",
    "    client_id= input(\"Enter client_id: \"),\n",
    "    client_secret= input(\"Enter client_secret: \"),\n",
    "    user_agent=\"stories\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddits = [\n",
    "    \"TIFU\", \"IAmA\", \"relationships\", \"nosleep\", \"prorevenge\",\n",
    "    \"casualconversation\", \"personalfinance\", \"confession\", \"MaliciousCompliance\",\n",
    "    \"AmItheAsshole\", \"JustNoMIL\", \"creepypasta\",\n",
    "    \"shortscarystories\", \"ScaryStories\", \"Paranormal\",\n",
    "    \"UnresolvedMysteries\", \"TalesFromRetail\", \"TalesFromTechSupport\",\n",
    "    \"TalesFromYourServer\", \"TalesFromTheFrontDesk\", \"TalesFromTheCustomer\",\n",
    "    \"TalesFromThePharmacy\", \"TalesFromThePizzaGuy\", \"TalesFromCallCenters\",\n",
    "    \"TalesFromTheSquadCar\"\n",
    "]\n",
    "\n",
    "\n",
    "attributes = [\n",
    "    'id', 'title', 'selftext', 'created_utc', 'subreddit',\n",
    "    'num_comments', 'score', 'upvote_ratio'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    data = []\n",
    "\n",
    "    for subreddit in subreddits:\n",
    "        current = reddit.subreddit(subreddit)\n",
    "        for post in current.top(limit=1000):\n",
    "            post_data = {attr: getattr(post, attr, None) for attr in attributes}\n",
    "            data.append(post_data)\n",
    "        time.sleep(60)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24353, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x35iu6</td>\n",
       "      <td>TIFU / My (20F) girlfriend of two years told m...</td>\n",
       "      <td>\\nA little back story; when I first started ha...</td>\n",
       "      <td>1.662033e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>4997</td>\n",
       "      <td>183765</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a99fw9</td>\n",
       "      <td>TIFU by buying everyone an AncestryDNA kit and...</td>\n",
       "      <td>Earlier this year, AncestryDNA had a sale on t...</td>\n",
       "      <td>1.545691e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>8828</td>\n",
       "      <td>173987</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ak2k64</td>\n",
       "      <td>TIFU by living in a dark bedroom for 6 years.</td>\n",
       "      <td>The overhead fan in our bedroom uses one of th...</td>\n",
       "      <td>1.548522e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>2566</td>\n",
       "      <td>148075</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bbgmzp</td>\n",
       "      <td>TIFU by spending the last year on reddit talki...</td>\n",
       "      <td>Today was the day I realised I messed up by no...</td>\n",
       "      <td>1.554862e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>3120</td>\n",
       "      <td>143727</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i3xnlq</td>\n",
       "      <td>TIFU by owning a Golden Retriever while being ...</td>\n",
       "      <td>Sigh. \\n\\nWork was rough today and all I wante...</td>\n",
       "      <td>1.596597e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>7084</td>\n",
       "      <td>139831</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  x35iu6  TIFU / My (20F) girlfriend of two years told m...   \n",
       "1  a99fw9  TIFU by buying everyone an AncestryDNA kit and...   \n",
       "2  ak2k64      TIFU by living in a dark bedroom for 6 years.   \n",
       "3  bbgmzp  TIFU by spending the last year on reddit talki...   \n",
       "4  i3xnlq  TIFU by owning a Golden Retriever while being ...   \n",
       "\n",
       "                                            selftext   created_utc subreddit  \\\n",
       "0  \\nA little back story; when I first started ha...  1.662033e+09      tifu   \n",
       "1  Earlier this year, AncestryDNA had a sale on t...  1.545691e+09      tifu   \n",
       "2  The overhead fan in our bedroom uses one of th...  1.548522e+09      tifu   \n",
       "3  Today was the day I realised I messed up by no...  1.554862e+09      tifu   \n",
       "4  Sigh. \\n\\nWork was rough today and all I wante...  1.596597e+09      tifu   \n",
       "\n",
       "   num_comments   score  upvote_ratio  \n",
       "0          4997  183765          0.95  \n",
       "1          8828  173987          0.95  \n",
       "2          2566  148075          0.96  \n",
       "3          3120  143727          0.95  \n",
       "4          7084  139831          0.90  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('stories.csv'):\n",
    "    df = pd.read_csv('stories.csv')\n",
    "else: \n",
    "    df = pd.DataFrame(get_data())\n",
    "    df.set_index('id', inplace=True)\n",
    "    \n",
    "print(df.shape) \n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions necessary to clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from textblob import TextBlob\n",
    "import re \n",
    "import textstat\n",
    "\n",
    "def calculate_downvotes(upvotes, upvote_ratio):\n",
    "      return upvotes/upvote_ratio - upvotes\n",
    "\n",
    "def convert_to_time(string):\n",
    "      return datetime.strptime(string, \"%H:%M\")\n",
    "\n",
    "def handle_date(created_time):\n",
    "      dt = datetime.fromtimestamp(created_time)\n",
    "      \n",
    "      date = f\"{str(dt.month).zfill(2)}-{str(dt.day).zfill(2)}-{dt.year}\"\n",
    "      time_of_day = convert_to_time(dt.strftime(\"%H:%M\"))\n",
    "      \n",
    "      if convert_to_time(\"00:00\") <= time_of_day <= convert_to_time(\"04:59\"):\n",
    "            time_of_day = \"Midnight\"\n",
    "      elif convert_to_time(\"05:00\") < time_of_day < convert_to_time(\"05:59\"):\n",
    "            time_of_day = \"Dawn\"\n",
    "      elif convert_to_time(\"06:00\") < time_of_day < convert_to_time(\"11:59\"):\n",
    "            time_of_day = \"Morning\"\n",
    "      elif convert_to_time(\"12:00\") < time_of_day < convert_to_time(\"12:59\"):\n",
    "            time_of_day = \"Noon\"\n",
    "      elif convert_to_time(\"13:00\") < time_of_day < convert_to_time(\"16:59\"):\n",
    "            time_of_day = \"Afternoon\"\n",
    "      elif convert_to_time(\"17:00\") < time_of_day < convert_to_time(\"18:59\"):\n",
    "            time_of_day = \"Evening\"\n",
    "      else:\n",
    "            time_of_day = \"Night\"\n",
    "\n",
    "      return {\"date\": date, \"time_of_day\": time_of_day}\n",
    "\n",
    "def get_word_list(string):\n",
    "      return re.findall(r\"\\b\\w[\\w'-]*\\b\", str(string))\n",
    "\n",
    "def divider(num1, num2):\n",
    "      return num1 / num2 if num2 > 0 else 0\n",
    "\n",
    "def get_avg_word_length(arr):\n",
    "      return round(divider(sum(len(word) for word in arr), len(arr)), 3)\n",
    "\n",
    "def get_sentences(string):\n",
    "      return TextBlob(string).sentences\n",
    "\n",
    "def get_sentiment(string):\n",
    "      return TextBlob(string).sentiment\n",
    "\n",
    "def get_syllable_count(string):\n",
    "      return textstat.syllable_count(string)\n",
    "\n",
    "def get_reading_score(string):\n",
    "      return textstat.flesch_reading_ease(string)\n",
    "\n",
    "def get_reading_grade(string):\n",
    "      return textstat.text_standard(string)\n",
    "\n",
    "def get_story_sent_info(sentences):\n",
    "      amount_sent = len(sentences)\n",
    "      words_in_sent = 0\n",
    "      syllables_in_sent = 0\n",
    "      polarity_sentences = 0\n",
    "      subjectivity_sentences = 0\n",
    "      reading_score_sentences = 0\n",
    "      \n",
    "      for sentence in sentences:\n",
    "            sent = str(sentence)\n",
    "            sentiment = get_sentiment(sent)\n",
    "            words_in_sent += len(get_word_list(sent))\n",
    "            syllables_in_sent += get_syllable_count(sent)\n",
    "            polarity_sentences += sentiment.polarity\n",
    "            subjectivity_sentences += sentiment.subjectivity\n",
    "            reading_score_sentences += get_reading_score(sent)\n",
    "      \n",
    "      return {\n",
    "            \"amount_sentences\": len(sentences),\n",
    "            \"avg_words_per_sentence\": round(divider(words_in_sent, amount_sent), 3),\n",
    "            \"avg_syllables_per_sentence\": round(divider(syllables_in_sent, amount_sent), 3),\n",
    "            \"avg_polarity_per_sentence\": round(divider(polarity_sentences, amount_sent), 3),\n",
    "            \"avg_subjectivity_per_sentence\": round(divider(subjectivity_sentences, amount_sent), 3),\n",
    "            \"avg_readscore_per_sentence\": round(divider(reading_score_sentences, amount_sent), 3)\n",
    "      } \n",
    "\n",
    "def info(string, isTitle):\n",
    "      words = get_word_list(string)\n",
    "      name = 'title' if isTitle else 'story'\n",
    "      \n",
    "      result =  {\n",
    "            f'{name}_length': len(string),\n",
    "            f'{name}_word_count': len(words),\n",
    "            f'{name}_avg_word_length': get_avg_word_length(words),\n",
    "            f'{name}_syllables': get_syllable_count(string),\n",
    "            f'{name}_reading_score': get_reading_score(string),\n",
    "            f'{name}_reading_grade': get_reading_grade(string),\n",
    "            f'{name}_polarity': round(get_sentiment(string).polarity, 3),\n",
    "            f'{name}_subjectivity': round(get_sentiment(string).subjectivity, 3)     \n",
    "      }\n",
    "      \n",
    "      if not isTitle:\n",
    "        result.update(get_story_sent_info(get_sentences(string)))\n",
    "      \n",
    "      return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22722, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x35iu6</td>\n",
       "      <td>TIFU / My (20F) girlfriend of two years told m...</td>\n",
       "      <td>\\nA little back story; when I first started ha...</td>\n",
       "      <td>1.662033e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>4997</td>\n",
       "      <td>183765</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a99fw9</td>\n",
       "      <td>TIFU by buying everyone an AncestryDNA kit and...</td>\n",
       "      <td>Earlier this year, AncestryDNA had a sale on t...</td>\n",
       "      <td>1.545691e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>8828</td>\n",
       "      <td>173987</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ak2k64</td>\n",
       "      <td>TIFU by living in a dark bedroom for 6 years.</td>\n",
       "      <td>The overhead fan in our bedroom uses one of th...</td>\n",
       "      <td>1.548522e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>2566</td>\n",
       "      <td>148075</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bbgmzp</td>\n",
       "      <td>TIFU by spending the last year on reddit talki...</td>\n",
       "      <td>Today was the day I realised I messed up by no...</td>\n",
       "      <td>1.554862e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>3120</td>\n",
       "      <td>143727</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i3xnlq</td>\n",
       "      <td>TIFU by owning a Golden Retriever while being ...</td>\n",
       "      <td>Sigh. \\n\\nWork was rough today and all I wante...</td>\n",
       "      <td>1.596597e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>7084</td>\n",
       "      <td>139831</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  x35iu6  TIFU / My (20F) girlfriend of two years told m...   \n",
       "1  a99fw9  TIFU by buying everyone an AncestryDNA kit and...   \n",
       "2  ak2k64      TIFU by living in a dark bedroom for 6 years.   \n",
       "3  bbgmzp  TIFU by spending the last year on reddit talki...   \n",
       "4  i3xnlq  TIFU by owning a Golden Retriever while being ...   \n",
       "\n",
       "                                            selftext   created_utc subreddit  \\\n",
       "0  \\nA little back story; when I first started ha...  1.662033e+09      tifu   \n",
       "1  Earlier this year, AncestryDNA had a sale on t...  1.545691e+09      tifu   \n",
       "2  The overhead fan in our bedroom uses one of th...  1.548522e+09      tifu   \n",
       "3  Today was the day I realised I messed up by no...  1.554862e+09      tifu   \n",
       "4  Sigh. \\n\\nWork was rough today and all I wante...  1.596597e+09      tifu   \n",
       "\n",
       "   num_comments   score  upvote_ratio  \n",
       "0          4997  183765          0.95  \n",
       "1          8828  173987          0.95  \n",
       "2          2566  148075          0.96  \n",
       "3          3120  143727          0.95  \n",
       "4          7084  139831          0.90  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['title'].str.len() > 0]\n",
    "df = df[df['selftext'].str.len() > 0]\n",
    "\n",
    "print(df.shape) \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying functions to clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22722, 33)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>downvotes</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>story_reading_score</th>\n",
       "      <th>story_reading_grade</th>\n",
       "      <th>story_polarity</th>\n",
       "      <th>story_subjectivity</th>\n",
       "      <th>amount_sentences</th>\n",
       "      <th>avg_words_per_sentence</th>\n",
       "      <th>avg_syllables_per_sentence</th>\n",
       "      <th>avg_polarity_per_sentence</th>\n",
       "      <th>avg_subjectivity_per_sentence</th>\n",
       "      <th>avg_readscore_per_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x35iu6</td>\n",
       "      <td>TIFU / My (20F) girlfriend of two years told m...</td>\n",
       "      <td>\\nA little back story; when I first started ha...</td>\n",
       "      <td>1.662033e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>4997</td>\n",
       "      <td>183765</td>\n",
       "      <td>0.95</td>\n",
       "      <td>9671</td>\n",
       "      <td>09-01-2022</td>\n",
       "      <td>...</td>\n",
       "      <td>75.44</td>\n",
       "      <td>7th and 8th grade</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.535</td>\n",
       "      <td>16</td>\n",
       "      <td>22.812</td>\n",
       "      <td>29.000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.504</td>\n",
       "      <td>77.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a99fw9</td>\n",
       "      <td>TIFU by buying everyone an AncestryDNA kit and...</td>\n",
       "      <td>Earlier this year, AncestryDNA had a sale on t...</td>\n",
       "      <td>1.545691e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>8828</td>\n",
       "      <td>173987</td>\n",
       "      <td>0.95</td>\n",
       "      <td>9157</td>\n",
       "      <td>12-24-2018</td>\n",
       "      <td>...</td>\n",
       "      <td>81.73</td>\n",
       "      <td>5th and 6th grade</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.447</td>\n",
       "      <td>26</td>\n",
       "      <td>14.423</td>\n",
       "      <td>18.808</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.264</td>\n",
       "      <td>76.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ak2k64</td>\n",
       "      <td>TIFU by living in a dark bedroom for 6 years.</td>\n",
       "      <td>The overhead fan in our bedroom uses one of th...</td>\n",
       "      <td>1.548522e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>2566</td>\n",
       "      <td>148075</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6169</td>\n",
       "      <td>01-26-2019</td>\n",
       "      <td>...</td>\n",
       "      <td>70.87</td>\n",
       "      <td>9th and 10th grade</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.510</td>\n",
       "      <td>14</td>\n",
       "      <td>23.857</td>\n",
       "      <td>29.857</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.516</td>\n",
       "      <td>76.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bbgmzp</td>\n",
       "      <td>TIFU by spending the last year on reddit talki...</td>\n",
       "      <td>Today was the day I realised I messed up by no...</td>\n",
       "      <td>1.554862e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>3120</td>\n",
       "      <td>143727</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7564</td>\n",
       "      <td>04-09-2019</td>\n",
       "      <td>...</td>\n",
       "      <td>70.13</td>\n",
       "      <td>8th and 9th grade</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.569</td>\n",
       "      <td>24</td>\n",
       "      <td>22.500</td>\n",
       "      <td>29.458</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.477</td>\n",
       "      <td>65.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i3xnlq</td>\n",
       "      <td>TIFU by owning a Golden Retriever while being ...</td>\n",
       "      <td>Sigh. \\n\\nWork was rough today and all I wante...</td>\n",
       "      <td>1.596597e+09</td>\n",
       "      <td>tifu</td>\n",
       "      <td>7084</td>\n",
       "      <td>139831</td>\n",
       "      <td>0.90</td>\n",
       "      <td>15536</td>\n",
       "      <td>08-04-2020</td>\n",
       "      <td>...</td>\n",
       "      <td>77.98</td>\n",
       "      <td>6th and 7th grade</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.438</td>\n",
       "      <td>70</td>\n",
       "      <td>18.657</td>\n",
       "      <td>23.571</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.289</td>\n",
       "      <td>78.577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                              title  \\\n",
       "0  x35iu6  TIFU / My (20F) girlfriend of two years told m...   \n",
       "1  a99fw9  TIFU by buying everyone an AncestryDNA kit and...   \n",
       "2  ak2k64      TIFU by living in a dark bedroom for 6 years.   \n",
       "3  bbgmzp  TIFU by spending the last year on reddit talki...   \n",
       "4  i3xnlq  TIFU by owning a Golden Retriever while being ...   \n",
       "\n",
       "                                            selftext   created_utc subreddit  \\\n",
       "0  \\nA little back story; when I first started ha...  1.662033e+09      tifu   \n",
       "1  Earlier this year, AncestryDNA had a sale on t...  1.545691e+09      tifu   \n",
       "2  The overhead fan in our bedroom uses one of th...  1.548522e+09      tifu   \n",
       "3  Today was the day I realised I messed up by no...  1.554862e+09      tifu   \n",
       "4  Sigh. \\n\\nWork was rough today and all I wante...  1.596597e+09      tifu   \n",
       "\n",
       "   num_comments   score  upvote_ratio  downvotes        date  ...  \\\n",
       "0          4997  183765          0.95       9671  09-01-2022  ...   \n",
       "1          8828  173987          0.95       9157  12-24-2018  ...   \n",
       "2          2566  148075          0.96       6169  01-26-2019  ...   \n",
       "3          3120  143727          0.95       7564  04-09-2019  ...   \n",
       "4          7084  139831          0.90      15536  08-04-2020  ...   \n",
       "\n",
       "  story_reading_score  story_reading_grade  story_polarity  \\\n",
       "0               75.44    7th and 8th grade           0.052   \n",
       "1               81.73    5th and 6th grade           0.143   \n",
       "2               70.87   9th and 10th grade           0.067   \n",
       "3               70.13    8th and 9th grade           0.122   \n",
       "4               77.98    6th and 7th grade           0.045   \n",
       "\n",
       "   story_subjectivity  amount_sentences  avg_words_per_sentence  \\\n",
       "0               0.535                16                  22.812   \n",
       "1               0.447                26                  14.423   \n",
       "2               0.510                14                  23.857   \n",
       "3               0.569                24                  22.500   \n",
       "4               0.438                70                  18.657   \n",
       "\n",
       "  avg_syllables_per_sentence  avg_polarity_per_sentence  \\\n",
       "0                     29.000                      0.040   \n",
       "1                     18.808                      0.063   \n",
       "2                     29.857                      0.017   \n",
       "3                     29.458                      0.083   \n",
       "4                     23.571                      0.048   \n",
       "\n",
       "   avg_subjectivity_per_sentence  avg_readscore_per_sentence  \n",
       "0                          0.504                      77.457  \n",
       "1                          0.264                      76.440  \n",
       "2                          0.516                      76.945  \n",
       "3                          0.477                      65.953  \n",
       "4                          0.289                      78.577  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['downvotes'] = calculate_downvotes(df['score'], df['upvote_ratio']).astype(int)\n",
    "\n",
    "df[['date', 'time_of_day']] = df['created_utc'].apply(lambda x: pd.Series(handle_date(x)))\n",
    "\n",
    "df[['title_length', 'title_word_count', 'title_avg_word_length', \n",
    "    'title_syllables', 'title_reading_score', 'title_reading_grade', \n",
    "    'title_polarity', 'title_subjectivity']\n",
    "   ] = df['title'].apply(lambda x: pd.Series(info(x, True)))\n",
    "\n",
    "df[['story_length', 'story_word_count', 'story_avg_word_length',\n",
    "    'story_syllables', 'story_reading_score', 'story_reading_grade',\n",
    "    'story_polarity', 'story_subjectivity', 'amount_sentences',\n",
    "    'avg_words_per_sentence', 'avg_syllables_per_sentence',\n",
    "    'avg_polarity_per_sentence', 'avg_subjectivity_per_sentence',\n",
    "    'avg_readscore_per_sentence']\n",
    "   ] = df['selftext'].apply(lambda x: pd.Series(info(x, False)))\n",
    "\n",
    "\n",
    "print(df.shape) \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>date</th>\n",
       "      <th>time_of_day</th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>title_avg_word_length</th>\n",
       "      <th>title_syllables</th>\n",
       "      <th>title_reading_score</th>\n",
       "      <th>title_reading_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>amount_sentences</th>\n",
       "      <th>avg_words_per_sentence</th>\n",
       "      <th>avg_syllables_per_sentence</th>\n",
       "      <th>avg_polarity_per_sentence</th>\n",
       "      <th>avg_subjectivity_per_sentence</th>\n",
       "      <th>avg_readscore_per_sentence</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>downvotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x35iu6</td>\n",
       "      <td>tifu</td>\n",
       "      <td>09-01-2022</td>\n",
       "      <td>Morning</td>\n",
       "      <td>116</td>\n",
       "      <td>24</td>\n",
       "      <td>3.625</td>\n",
       "      <td>29</td>\n",
       "      <td>80.96</td>\n",
       "      <td>8th and 9th grade</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>22.812</td>\n",
       "      <td>29.000</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.504</td>\n",
       "      <td>77.457</td>\n",
       "      <td>4997</td>\n",
       "      <td>183765</td>\n",
       "      <td>0.95</td>\n",
       "      <td>9671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a99fw9</td>\n",
       "      <td>tifu</td>\n",
       "      <td>12-24-2018</td>\n",
       "      <td>Evening</td>\n",
       "      <td>64</td>\n",
       "      <td>10</td>\n",
       "      <td>5.500</td>\n",
       "      <td>20</td>\n",
       "      <td>27.49</td>\n",
       "      <td>11th and 12th grade</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>14.423</td>\n",
       "      <td>18.808</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.264</td>\n",
       "      <td>76.440</td>\n",
       "      <td>8828</td>\n",
       "      <td>173987</td>\n",
       "      <td>0.95</td>\n",
       "      <td>9157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ak2k64</td>\n",
       "      <td>tifu</td>\n",
       "      <td>01-26-2019</td>\n",
       "      <td>Morning</td>\n",
       "      <td>45</td>\n",
       "      <td>10</td>\n",
       "      <td>3.500</td>\n",
       "      <td>13</td>\n",
       "      <td>86.71</td>\n",
       "      <td>3rd and 4th grade</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>23.857</td>\n",
       "      <td>29.857</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.516</td>\n",
       "      <td>76.945</td>\n",
       "      <td>2566</td>\n",
       "      <td>148075</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bbgmzp</td>\n",
       "      <td>tifu</td>\n",
       "      <td>04-09-2019</td>\n",
       "      <td>Night</td>\n",
       "      <td>77</td>\n",
       "      <td>14</td>\n",
       "      <td>4.500</td>\n",
       "      <td>22</td>\n",
       "      <td>57.27</td>\n",
       "      <td>5th and 6th grade</td>\n",
       "      <td>...</td>\n",
       "      <td>24</td>\n",
       "      <td>22.500</td>\n",
       "      <td>29.458</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.477</td>\n",
       "      <td>65.953</td>\n",
       "      <td>3120</td>\n",
       "      <td>143727</td>\n",
       "      <td>0.95</td>\n",
       "      <td>7564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i3xnlq</td>\n",
       "      <td>tifu</td>\n",
       "      <td>08-04-2020</td>\n",
       "      <td>Night</td>\n",
       "      <td>52</td>\n",
       "      <td>9</td>\n",
       "      <td>4.778</td>\n",
       "      <td>15</td>\n",
       "      <td>53.88</td>\n",
       "      <td>8th and 9th grade</td>\n",
       "      <td>...</td>\n",
       "      <td>70</td>\n",
       "      <td>18.657</td>\n",
       "      <td>23.571</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.289</td>\n",
       "      <td>78.577</td>\n",
       "      <td>7084</td>\n",
       "      <td>139831</td>\n",
       "      <td>0.90</td>\n",
       "      <td>15536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id subreddit        date time_of_day  title_length  title_word_count  \\\n",
       "0  x35iu6      tifu  09-01-2022     Morning           116                24   \n",
       "1  a99fw9      tifu  12-24-2018     Evening            64                10   \n",
       "2  ak2k64      tifu  01-26-2019     Morning            45                10   \n",
       "3  bbgmzp      tifu  04-09-2019       Night            77                14   \n",
       "4  i3xnlq      tifu  08-04-2020       Night            52                 9   \n",
       "\n",
       "   title_avg_word_length  title_syllables  title_reading_score  \\\n",
       "0                  3.625               29                80.96   \n",
       "1                  5.500               20                27.49   \n",
       "2                  3.500               13                86.71   \n",
       "3                  4.500               22                57.27   \n",
       "4                  4.778               15                53.88   \n",
       "\n",
       "   title_reading_grade  ...  amount_sentences  avg_words_per_sentence  \\\n",
       "0    8th and 9th grade  ...                16                  22.812   \n",
       "1  11th and 12th grade  ...                26                  14.423   \n",
       "2    3rd and 4th grade  ...                14                  23.857   \n",
       "3    5th and 6th grade  ...                24                  22.500   \n",
       "4    8th and 9th grade  ...                70                  18.657   \n",
       "\n",
       "   avg_syllables_per_sentence  avg_polarity_per_sentence  \\\n",
       "0                      29.000                      0.040   \n",
       "1                      18.808                      0.063   \n",
       "2                      29.857                      0.017   \n",
       "3                      29.458                      0.083   \n",
       "4                      23.571                      0.048   \n",
       "\n",
       "   avg_subjectivity_per_sentence  avg_readscore_per_sentence  num_comments  \\\n",
       "0                          0.504                      77.457          4997   \n",
       "1                          0.264                      76.440          8828   \n",
       "2                          0.516                      76.945          2566   \n",
       "3                          0.477                      65.953          3120   \n",
       "4                          0.289                      78.577          7084   \n",
       "\n",
       "  upvotes  upvote_ratio  downvotes  \n",
       "0  183765          0.95       9671  \n",
       "1  173987          0.95       9157  \n",
       "2  148075          0.96       6169  \n",
       "3  143727          0.95       7564  \n",
       "4  139831          0.90      15536  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={\"score\": \"upvotes\"})\n",
    "\n",
    "columns = [\n",
    "    'id', 'subreddit', 'date', 'time_of_day',\n",
    "    'title_length', 'title_word_count', 'title_avg_word_length',\n",
    "    'title_syllables', 'title_reading_score', 'title_reading_grade',\n",
    "    'title_polarity', 'title_subjectivity', 'story_length',\n",
    "    'story_word_count', 'story_avg_word_length', 'story_syllables',\n",
    "    'story_reading_score', 'story_reading_grade', 'story_polarity',\n",
    "    'story_subjectivity', 'amount_sentences', 'avg_words_per_sentence',\n",
    "    'avg_syllables_per_sentence', 'avg_polarity_per_sentence',\n",
    "    'avg_subjectivity_per_sentence', 'avg_readscore_per_sentence',\n",
    "    'num_comments', 'upvotes', 'upvote_ratio', 'downvotes'\n",
    "]\n",
    "\n",
    "df = df[columns]\n",
    "\n",
    "df.head(5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
